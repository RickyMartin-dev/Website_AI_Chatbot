{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "bedrock = boto3.client('bedrock', region_name=os.getenv(\"AWS_REGION\"))\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=os.getenv(\"AWS_REGION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Model Specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large', 'modelId': 'amazon.titan-tg1-large', 'modelName': 'Titan Text Large', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0', 'modelId': 'amazon.titan-image-generator-v1:0', 'modelName': 'Titan Image Generator G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1', 'modelId': 'amazon.titan-image-generator-v1', 'modelName': 'Titan Image Generator G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v2:0', 'modelId': 'amazon.titan-image-generator-v2:0', 'modelName': 'Titan Image Generator G1 v2', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED', 'ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:8k', 'modelId': 'amazon.nova-premier-v1:0:8k', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:20k', 'modelId': 'amazon.nova-premier-v1:0:20k', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:1000k', 'modelId': 'amazon.nova-premier-v1:0:1000k', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:mm', 'modelId': 'amazon.nova-premier-v1:0:mm', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0', 'modelId': 'amazon.nova-premier-v1:0', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-premier-v1:0', 'modelId': 'amazon.titan-text-premier-v1:0', 'modelName': 'Titan Text G1 - Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:24k', 'modelId': 'amazon.nova-pro-v1:0:24k', 'modelName': 'Nova Pro', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:300k', 'modelId': 'amazon.nova-pro-v1:0:300k', 'modelName': 'Nova Pro', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'DISTILLATION'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0', 'modelId': 'amazon.nova-pro-v1:0', 'modelName': 'Nova Pro', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:24k', 'modelId': 'amazon.nova-lite-v1:0:24k', 'modelName': 'Nova Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:300k', 'modelId': 'amazon.nova-lite-v1:0:300k', 'modelName': 'Nova Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'DISTILLATION'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0', 'modelId': 'amazon.nova-lite-v1:0', 'modelName': 'Nova Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-canvas-v1:0', 'modelId': 'amazon.nova-canvas-v1:0', 'modelName': 'Nova Canvas', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'responseStreamingSupported': False, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:0', 'modelId': 'amazon.nova-reel-v1:0', 'modelName': 'Nova Reel', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['VIDEO'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:1', 'modelId': 'amazon.nova-reel-v1:1', 'modelName': 'Nova Reel', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['VIDEO'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:24k', 'modelId': 'amazon.nova-micro-v1:0:24k', 'modelName': 'Nova Micro', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:128k', 'modelId': 'amazon.nova-micro-v1:0:128k', 'modelName': 'Nova Micro', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'DISTILLATION'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0', 'modelId': 'amazon.nova-micro-v1:0', 'modelName': 'Nova Micro', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-sonic-v1:0', 'modelId': 'amazon.nova-sonic-v1:0', 'modelName': 'Nova Sonic', 'providerName': 'Amazon', 'inputModalities': ['SPEECH'], 'outputModalities': ['SPEECH', 'TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02', 'modelId': 'amazon.titan-embed-g1-text-02', 'modelName': 'Titan Text Embeddings v2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k', 'modelId': 'amazon.titan-text-lite-v1:0:4k', 'modelName': 'Titan Text G1 - Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1', 'modelId': 'amazon.titan-text-lite-v1', 'modelName': 'Titan Text G1 - Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k', 'modelId': 'amazon.titan-text-express-v1:0:8k', 'modelName': 'Titan Text G1 - Express', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1', 'modelId': 'amazon.titan-text-express-v1', 'modelName': 'Titan Text G1 - Express', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k', 'modelId': 'amazon.titan-embed-text-v1:2:8k', 'modelName': 'Titan Embeddings G1 - Text', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1', 'modelId': 'amazon.titan-embed-text-v1', 'modelName': 'Titan Embeddings G1 - Text', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0:8k', 'modelId': 'amazon.titan-embed-text-v2:0:8k', 'modelName': 'Titan Text Embeddings V2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0', 'modelId': 'amazon.titan-embed-text-v2:0', 'modelName': 'Titan Text Embeddings V2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0', 'modelId': 'amazon.titan-embed-image-v1:0', 'modelName': 'Titan Multimodal Embeddings G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1', 'modelId': 'amazon.titan-embed-image-v1', 'modelName': 'Titan Multimodal Embeddings G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0', 'modelId': 'stability.stable-diffusion-xl-v1:0', 'modelName': 'SDXL 1.0', 'providerName': 'Stability AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1', 'modelId': 'stability.stable-diffusion-xl-v1', 'modelName': 'SDXL 1.0', 'providerName': 'Stability AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-instruct-v1:0', 'modelId': 'ai21.jamba-instruct-v1:0', 'modelName': 'Jamba-Instruct', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-large-v1:0', 'modelId': 'ai21.jamba-1-5-large-v1:0', 'modelName': 'Jamba 1.5 Large', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-mini-v1:0', 'modelId': 'ai21.jamba-1-5-mini-v1:0', 'modelName': 'Jamba 1.5 Mini', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k', 'modelId': 'anthropic.claude-instant-v1:2:100k', 'modelName': 'Claude Instant', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1', 'modelId': 'anthropic.claude-instant-v1', 'modelName': 'Claude Instant', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k', 'modelId': 'anthropic.claude-v2:0:18k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k', 'modelId': 'anthropic.claude-v2:0:100k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k', 'modelId': 'anthropic.claude-v2:1:18k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k', 'modelId': 'anthropic.claude-v2:1:200k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1', 'modelId': 'anthropic.claude-v2:1', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2', 'modelId': 'anthropic.claude-v2', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:28k', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:200k', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:48k', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:200k', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:12k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:28k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:200k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0', 'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'modelName': 'Claude 3.5 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20241022-v2:0', 'modelId': 'anthropic.claude-3-5-sonnet-20241022-v2:0', 'modelName': 'Claude 3.5 Sonnet v2', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-7-sonnet-20250219-v1:0', 'modelId': 'anthropic.claude-3-7-sonnet-20250219-v1:0', 'modelName': 'Claude 3.7 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-haiku-20241022-v1:0', 'modelId': 'anthropic.claude-3-5-haiku-20241022-v1:0', 'modelName': 'Claude 3.5 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-20250514-v1:0', 'modelId': 'anthropic.claude-opus-4-20250514-v1:0', 'modelName': 'Claude Opus 4', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-sonnet-4-20250514-v1:0', 'modelId': 'anthropic.claude-sonnet-4-20250514-v1:0', 'modelName': 'Claude Sonnet 4', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k', 'modelId': 'cohere.command-text-v14:7:4k', 'modelName': 'Command', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14', 'modelId': 'cohere.command-text-v14', 'modelName': 'Command', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-v1:0', 'modelId': 'cohere.command-r-v1:0', 'modelName': 'Command R', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-plus-v1:0', 'modelId': 'cohere.command-r-plus-v1:0', 'modelName': 'Command R+', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k', 'modelId': 'cohere.command-light-text-v14:7:4k', 'modelName': 'Command Light', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14', 'modelId': 'cohere.command-light-text-v14', 'modelName': 'Command Light', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3:0:512', 'modelId': 'cohere.embed-english-v3:0:512', 'modelName': 'Embed English', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3', 'modelId': 'cohere.embed-english-v3', 'modelName': 'Embed English', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3:0:512', 'modelId': 'cohere.embed-multilingual-v3:0:512', 'modelName': 'Embed Multilingual', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3', 'modelId': 'cohere.embed-multilingual-v3', 'modelName': 'Embed Multilingual', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/deepseek.r1-v1:0', 'modelId': 'deepseek.r1-v1:0', 'modelName': 'DeepSeek-R1', 'providerName': 'DeepSeek', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0', 'modelId': 'meta.llama3-8b-instruct-v1:0', 'modelName': 'Llama 3 8B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0', 'modelId': 'meta.llama3-70b-instruct-v1:0', 'modelName': 'Llama 3 70B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-8b-instruct-v1:0', 'modelId': 'meta.llama3-1-8b-instruct-v1:0', 'modelName': 'Llama 3.1 8B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-70b-instruct-v1:0', 'modelId': 'meta.llama3-1-70b-instruct-v1:0', 'modelName': 'Llama 3.1 70B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-11b-instruct-v1:0', 'modelId': 'meta.llama3-2-11b-instruct-v1:0', 'modelName': 'Llama 3.2 11B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-90b-instruct-v1:0', 'modelId': 'meta.llama3-2-90b-instruct-v1:0', 'modelName': 'Llama 3.2 90B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-1b-instruct-v1:0', 'modelId': 'meta.llama3-2-1b-instruct-v1:0', 'modelName': 'Llama 3.2 1B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-3b-instruct-v1:0', 'modelId': 'meta.llama3-2-3b-instruct-v1:0', 'modelName': 'Llama 3.2 3B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-3-70b-instruct-v1:0', 'modelId': 'meta.llama3-3-70b-instruct-v1:0', 'modelName': 'Llama 3.3 70B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0', 'modelId': 'meta.llama4-scout-17b-instruct-v1:0', 'modelName': 'Llama 4 Scout 17B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-maverick-17b-instruct-v1:0', 'modelId': 'meta.llama4-maverick-17b-instruct-v1:0', 'modelName': 'Llama 4 Maverick 17B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-7b-instruct-v0:2', 'modelId': 'mistral.mistral-7b-instruct-v0:2', 'modelName': 'Mistral 7B Instruct', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mixtral-8x7b-instruct-v0:1', 'modelId': 'mistral.mixtral-8x7b-instruct-v0:1', 'modelName': 'Mixtral 8x7B Instruct', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-2402-v1:0', 'modelId': 'mistral.mistral-large-2402-v1:0', 'modelName': 'Mistral Large (24.02)', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-small-2402-v1:0', 'modelId': 'mistral.mistral-small-2402-v1:0', 'modelName': 'Mistral Small (24.02)', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.pixtral-large-2502-v1:0', 'modelId': 'mistral.pixtral-large-2502-v1:0', 'modelName': 'Pixtral Large (25.02)', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n"
     ]
    }
   ],
   "source": [
    "response = bedrock.list_foundation_models()\n",
    "models = response['modelSummaries']\n",
    "\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon.titan-tg1-large', 'amazon.titan-image-generator-v1:0', 'amazon.titan-image-generator-v1', 'amazon.titan-image-generator-v2:0', 'amazon.nova-premier-v1:0:8k', 'amazon.nova-premier-v1:0:20k', 'amazon.nova-premier-v1:0:1000k', 'amazon.nova-premier-v1:0:mm', 'amazon.nova-premier-v1:0', 'amazon.titan-text-premier-v1:0', 'amazon.nova-pro-v1:0:24k', 'amazon.nova-pro-v1:0:300k', 'amazon.nova-pro-v1:0', 'amazon.nova-lite-v1:0:24k', 'amazon.nova-lite-v1:0:300k', 'amazon.nova-lite-v1:0', 'amazon.nova-canvas-v1:0', 'amazon.nova-reel-v1:0', 'amazon.nova-reel-v1:1', 'amazon.nova-micro-v1:0:24k', 'amazon.nova-micro-v1:0:128k', 'amazon.nova-micro-v1:0', 'amazon.nova-sonic-v1:0', 'amazon.titan-embed-g1-text-02', 'amazon.titan-text-lite-v1:0:4k', 'amazon.titan-text-lite-v1', 'amazon.titan-text-express-v1:0:8k', 'amazon.titan-text-express-v1', 'amazon.titan-embed-text-v1:2:8k', 'amazon.titan-embed-text-v1', 'amazon.titan-embed-text-v2:0:8k', 'amazon.titan-embed-text-v2:0', 'amazon.titan-embed-image-v1:0', 'amazon.titan-embed-image-v1', 'stability.stable-diffusion-xl-v1:0', 'stability.stable-diffusion-xl-v1', 'ai21.jamba-instruct-v1:0', 'ai21.jamba-1-5-large-v1:0', 'ai21.jamba-1-5-mini-v1:0', 'anthropic.claude-instant-v1:2:100k', 'anthropic.claude-instant-v1', 'anthropic.claude-v2:0:18k', 'anthropic.claude-v2:0:100k', 'anthropic.claude-v2:1:18k', 'anthropic.claude-v2:1:200k', 'anthropic.claude-v2:1', 'anthropic.claude-v2', 'anthropic.claude-3-sonnet-20240229-v1:0:28k', 'anthropic.claude-3-sonnet-20240229-v1:0:200k', 'anthropic.claude-3-sonnet-20240229-v1:0', 'anthropic.claude-3-haiku-20240307-v1:0:48k', 'anthropic.claude-3-haiku-20240307-v1:0:200k', 'anthropic.claude-3-haiku-20240307-v1:0', 'anthropic.claude-3-opus-20240229-v1:0:12k', 'anthropic.claude-3-opus-20240229-v1:0:28k', 'anthropic.claude-3-opus-20240229-v1:0:200k', 'anthropic.claude-3-opus-20240229-v1:0', 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'anthropic.claude-3-5-sonnet-20241022-v2:0', 'anthropic.claude-3-7-sonnet-20250219-v1:0', 'anthropic.claude-3-5-haiku-20241022-v1:0', 'anthropic.claude-opus-4-20250514-v1:0', 'anthropic.claude-sonnet-4-20250514-v1:0', 'cohere.command-text-v14:7:4k', 'cohere.command-text-v14', 'cohere.command-r-v1:0', 'cohere.command-r-plus-v1:0', 'cohere.command-light-text-v14:7:4k', 'cohere.command-light-text-v14', 'cohere.embed-english-v3:0:512', 'cohere.embed-english-v3', 'cohere.embed-multilingual-v3:0:512', 'cohere.embed-multilingual-v3', 'deepseek.r1-v1:0', 'meta.llama3-8b-instruct-v1:0', 'meta.llama3-70b-instruct-v1:0', 'meta.llama3-1-8b-instruct-v1:0', 'meta.llama3-1-70b-instruct-v1:0', 'meta.llama3-2-11b-instruct-v1:0', 'meta.llama3-2-90b-instruct-v1:0', 'meta.llama3-2-1b-instruct-v1:0', 'meta.llama3-2-3b-instruct-v1:0', 'meta.llama3-3-70b-instruct-v1:0', 'meta.llama4-scout-17b-instruct-v1:0', 'meta.llama4-maverick-17b-instruct-v1:0', 'mistral.mistral-7b-instruct-v0:2', 'mistral.mixtral-8x7b-instruct-v0:1', 'mistral.mistral-large-2402-v1:0', 'mistral.mistral-small-2402-v1:0', 'mistral.pixtral-large-2502-v1:0']\n"
     ]
    }
   ],
   "source": [
    "response = bedrock.list_foundation_models()\n",
    "print([model[\"modelId\"] for model in response[\"modelSummaries\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple App Testing using Langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrock_llm(model_id: str = \"anthropic.claude-3-haiku-20240307-v1:0\", temp: float = 0.7, max_tokens: int = 2048):\n",
    "    \"\"\"Initialize a Bedrock LLM instance with the specific model\"\"\"\n",
    "    llm = ChatBedrock(client=bedrock_runtime,\n",
    "        model_id=model_id,\n",
    "        streaming=True,\n",
    "        model_kwargs=dict(temperature=temp, max_tokens=max_tokens))\n",
    "    return llm\n",
    "\n",
    "llm = get_bedrock_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm doing well, thank you for asking! As an AI language model, I don't have feelings or a physical state, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\", additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None, 'model_name': 'anthropic.claude-3-haiku-20240307-v1:0'}, id='run--85ac8889-d400-4af7-bc18-f30b0794000c-0', usage_metadata={'input_tokens': 12, 'output_tokens': 55, 'total_tokens': 67, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing The Actual App/Graph Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, boto3, json\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a pirate assistant.\n",
      "USER: Ahoy! How are ye?\n",
      "ASSISTANT:  I'm doing well, thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\")\n",
    "MODEL_ID = \"anthropic.claude-v2\"#\"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "DEFAULT_SYSTEM_PROMPT = os.getenv(\"DEFAULT_SYSTEM_PROMPT\", \"You are a helpful assistant.\")\n",
    "\n",
    "# Load config\n",
    "load_dotenv()\n",
    "\n",
    "# Bedrock call\n",
    "def get_bedrock_response(prompt: str, temperature=0.7, max_tokens=300):\n",
    "    bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    body = {\n",
    "        \"prompt\": f\"\\n\\nHuman: {prompt}\\n\\nAssistant:\",\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens_to_sample\": max_tokens\n",
    "    }\n",
    "    resp = bedrock.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "    return json.loads(resp[\"body\"].read())[\"completion\"]\n",
    "\n",
    "# TypedDict for state\n",
    "class ChatState(TypedDict):\n",
    "    messages: list[dict]\n",
    "\n",
    "# Node definition\n",
    "def call_llm_node(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    reply = get_bedrock_response(user_msg)\n",
    "    # Append assistant message\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "# Build the graph\n",
    "def build_graph():\n",
    "    builder = StateGraph(ChatState)\n",
    "    builder.add_node(\"call_llm\", call_llm_node)\n",
    "\n",
    "    # Core routing\n",
    "    builder.add_edge(START, \"call_llm\")\n",
    "    builder.set_finish_point(\"call_llm\")  # Halts after the node\n",
    "    return builder.compile()\n",
    "\n",
    "# Instantiate graph\n",
    "graph = build_graph()\n",
    "\n",
    "# Run a conversation\n",
    "def run_conversation(initial_messages: list[dict]) -> list[dict]:\n",
    "    # initial_messages includes system + user\n",
    "    state: ChatState = {\"messages\": initial_messages.copy()}\n",
    "    result = graph.invoke(state)\n",
    "    return result[\"messages\"]\n",
    "\n",
    "# Test example\n",
    "initial = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Ahoy! How are ye?\"}\n",
    "]\n",
    "chat = run_conversation(initial)\n",
    "for m in chat:\n",
    "    print(f\"{m['role'].upper()}: {m['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a pirate assistant.\n",
      "USER: Ahoy! How are ye?\n",
      "ASSISTANT: *tips pirate hat* Ahoy there, matey! As chipper as a pirate with a chest full of doubloons. How be ye faring on this fine day? Ready to set sail on some high seas adventures?\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\")\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "DEFAULT_SYSTEM_PROMPT = os.getenv(\"DEFAULT_SYSTEM_PROMPT\", \"You are a helpful assistant.\")\n",
    "\n",
    "# Load config\n",
    "load_dotenv()\n",
    "\n",
    "# Bedrock call\n",
    "def get_bedrock_response(prompt: str, temperature=0.7, max_tokens=300):\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    response = client.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    result = json.loads(response[\"body\"].read())\n",
    "    return result[\"content\"][0][\"text\"]  # Extract response\n",
    "\n",
    "# TypedDict for state\n",
    "class ChatState(TypedDict):\n",
    "    messages: list[dict]\n",
    "\n",
    "# Node definition\n",
    "def call_llm_node(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    reply = get_bedrock_response(user_msg)\n",
    "    # Append assistant message\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "# Build the graph\n",
    "def build_graph():\n",
    "    builder = StateGraph(ChatState)\n",
    "    builder.add_node(\"call_llm\", call_llm_node)\n",
    "\n",
    "    # Core routing\n",
    "    builder.add_edge(START, \"call_llm\")\n",
    "    builder.set_finish_point(\"call_llm\")  # Halts after the node\n",
    "    return builder.compile()\n",
    "\n",
    "# Instantiate graph\n",
    "graph = build_graph()\n",
    "\n",
    "# Run a conversation\n",
    "def run_conversation(initial_messages: list[dict]) -> list[dict]:\n",
    "    # initial_messages includes system + user\n",
    "    state: ChatState = {\"messages\": initial_messages.copy()}\n",
    "    result = graph.invoke(state)\n",
    "    return result[\"messages\"]\n",
    "\n",
    "# Test example\n",
    "initial = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Ahoy! How are ye?\"}\n",
    "]\n",
    "chat = run_conversation(initial)\n",
    "for m in chat:\n",
    "    print(f\"{m['role'].upper()}: {m['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a pirate assistant.\n",
      "USER: Why is the ocean blue?\n",
      "ASSISTANT: The ocean appears blue because of a phenomenon called scattering, where shorter (blue) wavelengths of light are dispersed more than longer (red) wavelengths by the tiny molecules of gases in the atmosphere and by the water itself. Here's a more detailed explanation:\n",
      "\n",
      "1. **Sunlight and the atmosphere**: When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2). These molecules scatter the shorter wavelengths of light, like blue and violet, more than the longer wavelengths, like red and orange. This is known as Rayleigh scattering.\n",
      "\n",
      "2. **Scattering in the ocean**: Once the light penetrates the ocean's surface, it continues to scatter. Water molecules and other substances in the ocean scatter the light in all directions. Again, the shorter wavelengths (like blue light) are scattered more than the longer wavelengths.\n",
      "\n",
      "3. **Absorption by water**: Water itself absorbs light, but it absorbs longer wavelengths (like red and infrared) more than the shorter wavelengths (like blue and violet). This means that as light travels through the water, the red light is absorbed, leaving mainly blue light to be scattered and reach our eyes.\n",
      "\n",
      "4. **Other factors**: While the basic reason for the ocean's blue color is the scattering and absorption of light, other factors can influence the color we perceive. These include the presence of sediments, algae, or other substances that can absorb or scatter light in different ways. For example, high concentrations of phytoplankton can give the ocean a greenish hue.\n",
      "\n",
      "In summary, the ocean appears blue primarily because of the scattering of sunlight by the atmosphere and the water itself, combined with the absorption of longer wavelengths by water. This results in the blue color being predominant as it is scattered in all directions and reaches our eyes from the ocean.\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = os.getenv(\"MODEL_PROFILE_ID\", \"us.meta.llama4-maverick-17b-instruct-v1:0\")\n",
    "\n",
    "# Define state schema\n",
    "class ChatState(TypedDict):\n",
    "    messages: list[dict]\n",
    "\n",
    "# Bedrock request with inference profile\n",
    "def get_bedrock_response(prompt: str, temperature=0.5, max_gen_len=512, top_p=0.9):\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    formatted = (\n",
    "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\"\n",
    "        \"You are a helpful assistant.\\n<|eot_id|>\\n\"\n",
    "        + \"\".join(\n",
    "            f\"<|start_header_id|>{m['role']}<|end_header_id|>\\n{m['content']}\\n<|eot_id|>\\n\"\n",
    "            for m in [{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        + \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    )\n",
    "    body = {\n",
    "        \"prompt\": formatted,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_gen_len\": max_gen_len,\n",
    "        \"top_p\": top_p\n",
    "    }\n",
    "    resp = client.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    data = json.loads(resp[\"body\"].read())\n",
    "    return data.get(\"generation\", \"\").strip()\n",
    "\n",
    "# LangGraph node\n",
    "def call_llm_node(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    reply = get_bedrock_response(user_msg)\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return state\n",
    "\n",
    "# Build graph\n",
    "def build_graph():\n",
    "    builder = StateGraph(ChatState)\n",
    "    builder.add_node(\"call_llm\", call_llm_node)\n",
    "    builder.add_edge(START, \"call_llm\")\n",
    "    builder.set_finish_point(\"call_llm\")\n",
    "    return builder.compile()\n",
    "\n",
    "graph = build_graph()\n",
    "\n",
    "# Conversation runner\n",
    "def run_conversation(initial_messages: list[dict]) -> list[dict]:\n",
    "    state: ChatState = {\"messages\": initial_messages.copy()}\n",
    "    return graph.invoke(state)[\"messages\"]\n",
    "\n",
    "# Test it\n",
    "initial = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Why is the ocean blue?\"}\n",
    "]\n",
    "chat = run_conversation(initial)\n",
    "for m in chat:\n",
    "    print(f\"{m['role'].upper()}: {m['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langgraph + Memory + better code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid, json, boto3\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "load_dotenv()\n",
    "\n",
    "# --- Config ---\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "DEFAULT_SYSTEM_PROMPT = os.getenv(\"DEFAULT_SYSTEM_PROMPT\", \"You are a helpful assistant.\")\n",
    "\n",
    "\n",
    "# --- Bedrock Claude Call ---\n",
    "def get_bedrock_response(prompt: str, temperature=0.7, max_tokens=300):\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    response = client.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    result = json.loads(response[\"body\"].read())\n",
    "    return result[\"content\"][0][\"text\"]\n",
    "\n",
    "\n",
    "\n",
    "# --- Memory Store ---\n",
    "class MemoryStore:\n",
    "    def __init__(self):\n",
    "        self._store: Dict[str, List[BaseMessage]] = {}\n",
    "\n",
    "    def get_history(self, session_id: str) -> List[BaseMessage]:\n",
    "        return self._store.get(session_id, [])\n",
    "\n",
    "    def append(self, session_id: str, message: BaseMessage):\n",
    "        if session_id not in self._store:\n",
    "            self._store[session_id] = []\n",
    "        self._store[session_id].append(message)\n",
    "\n",
    "    def set_history(self, session_id: str, messages: List[BaseMessage]):\n",
    "        self._store[session_id] = messages\n",
    "\n",
    "\n",
    "\n",
    "# --- Chat Agent ---\n",
    "class ChatAgent:\n",
    "    def __init__(self, system_prompt: str = \"You are a helpful assistant.\"):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.memory = MemoryStore()\n",
    "        self.graph = self.build_graph()\n",
    "\n",
    "    def _messages_to_prompt(self, messages: List[BaseMessage]) -> str:\n",
    "        \"\"\"Format messages into a single string prompt for Claude\"\"\"\n",
    "        parts = []\n",
    "        for msg in messages:\n",
    "            if isinstance(msg, SystemMessage):\n",
    "                continue  # Claude doesn't use this\n",
    "            role = \"Human\" if isinstance(msg, HumanMessage) else \"Assistant\"\n",
    "            parts.append(f\"\\n\\n{role}: {msg.content}\")\n",
    "        parts.append(\"\\n\\nAssistant:\")\n",
    "        return \"\".join(parts)\n",
    "\n",
    "    def build_graph(self):\n",
    "        def node(state: dict) -> dict:\n",
    "            session_id = state[\"session_id\"]\n",
    "            user_input = state[\"input\"]\n",
    "            messages = self.memory.get_history(session_id)\n",
    "\n",
    "            # Add system prompt once\n",
    "            if not messages or not isinstance(messages[0], SystemMessage):\n",
    "                messages.insert(0, SystemMessage(content=self.system_prompt))\n",
    "\n",
    "            messages.append(HumanMessage(content=user_input))\n",
    "            prompt = self._messages_to_prompt(messages)\n",
    "\n",
    "            # Use Bedrock to get response\n",
    "            response_text = get_bedrock_response(prompt)\n",
    "\n",
    "            messages.append(AIMessage(content=response_text))\n",
    "            self.memory.set_history(session_id, messages)\n",
    "\n",
    "            return {\n",
    "                \"session_id\": session_id,\n",
    "                \"messages\": messages,\n",
    "                \"output\": response_text\n",
    "            }\n",
    "\n",
    "        builder = StateGraph(state_schema=dict)\n",
    "        builder.add_node(\"chat\", RunnableLambda(node))\n",
    "        builder.add_edge(START, \"chat\")\n",
    "        builder.add_edge(\"chat\", END)\n",
    "        return builder.compile()\n",
    "\n",
    "    def chat(self, user_input: str, session_id: str = None) -> dict:\n",
    "        if not session_id:\n",
    "            session_id = str(uuid.uuid4())\n",
    "        return self.graph.invoke({\"input\": user_input, \"session_id\": session_id})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Chat Session (Notebook Wrapper) ---\n",
    "class ChatSession:\n",
    "    def __init__(self, agent: ChatAgent, session_id: str = None):\n",
    "        self.agent = agent\n",
    "        self.session_id = session_id or str(uuid.uuid4())\n",
    "\n",
    "    def send(self, user_input: str) -> str:\n",
    "        result = self.agent.chat(user_input, self.session_id)\n",
    "        return result[\"output\"]\n",
    "\n",
    "    def history(self) -> List[str]:\n",
    "        return [\n",
    "            f\"{'You' if isinstance(m, HumanMessage) else 'Bot'}: {m.content}\"\n",
    "            for m in self.agent.memory.get_history(self.session_id)\n",
    "            if isinstance(m, (HumanMessage, AIMessage))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatAgent(system_prompt=\"You are a witty, sarcastic assistant who always answers in riddles.\")\n",
    "session = ChatSession(agent, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAAAXNSR0IArs4c6QAAFKFJREFUeJztnXl8FEW+wKun574zkwk5hpDLYBISjgkEwawI4VpQFmS5VXR5PkDxIbosyooKojwXVhEUiHggLypPnlwhEPWBEu4ASTgiCQkk5Jock0zmnunu6f1jMB/EuZLqyUzY+v416equ+eU71d3VVdVVGE3TANFTWMEOoG+D9EGB9EGB9EGB9EGB9EHBhjxeW2MzGyibmbJZKIroG3UgnIPxhThfhItleL8BfJissJ7V+25dNd+8aq6+bJLI2VIFhy/C+SIWh9s3yjLhcNrMTquZMugIcyeZOFicMEgUlybqQVbd1tdSZ//p2xbC7hyYKU0aIparOD341tBB30rcKDFWXDDyBKwxf45QqXndOrwb+iiCPvFda+11S9YkRUqWtEfRhi7XzhjOH9UlpIsfmany/yh/9VlN1KHcxn4D+I880Y3c+xYUQZ/Y19rWYJ/6H9ECMe7PIX7p0zU5Dm5vGDImbOijcibiDGku/thx+WTntMXRikiuz5196zN3kt9srMueHp48TMJckCFNxQXj6fy2WStiRVIfZdDHvZJ0OA/uaMzIlv37uAMADMyUpD0kO5TbQJE+ypYPfeeOtstVnOETFIyG1wcYMVEhlrPPF7Z7382bvs424nqxMWd+JNOx9Q0mLIj85bzB2EF62cebvpP724ZPUHC4WABi6wNw+axhj4YV7W/1so9HfZ1tRFuTPX20LDCx9Q0ysuXNtXYvBdCjvhslpvTRMqxvPIYFChYO0kfLbpQYPe7gKaGqzDggpSePgTCMGTNGq9V296hvvvlm7dq1gYkIDEgRVpWaPKW612fSk1YjpYzyXW9kkPr6epPJY6BeKC8vD0A4d1CpeYZ20tP5677BqqnG1t2HZ/+haTovL6+goKC2tjYxMXHkyJGLFy++ePHikiVLAABTp04dM2bMxo0bq6qq9u7dW1xcrNVqExMTn3jiiWnTpgEAKisr582bt3nz5rfeeisiIkIgEJSUlAAADh48+NVXXyUnJzMecISa11Jnl4S5ceVen91MCSSwTYGeyMvL27Vr18KFCxMTExsbGz/66COZTDZ//vz333//pZdeys/Pj4yMBABs2rSpubn51VdfxTCsurp63bp1sbGxQ4cO5XK5AICdO3c+88wzgwcPTk1Nfeqpp5KSktasWROggAUS3G6h3CZ50Gd1Cv17Zu4BpaWlgwYNmj9/vuvPzMxMh8Px+902bNhgsViioqJc++zbt+/UqVNDhw51pY4aNWru3LkBivAeBGLcbnW6TXKvz+mkcU6gqnvp6enbtm1bt26dRqPJzs6OjY31EIMzLy/v9OnTt2/fdm1JTU3tSk1JSQlQeL+Hw2V5enpzr08gwtua3JQIRliwYIFEIjl+/PiaNWvYbPbkyZNffPHFsLCwu/ehKGrZsmU0TS9btmzEiBEikWjBggWuJAzDAAB8PlQje7ewGMmI/u6/zr0+oYRtqbQEKBocx2fMmDFjxozq6urz58/v2LHDZrO9++67d+9TXl5+/fr1HTt2aDQa15aum3LvjyqxGCihxP2lzEPpk+BWo/uLJTz5+flpaWnx8fGJiYmJiYk6ne7HH3/sKlYujEYjAEClutM0W1FRUV9f33Xhu4e7DwwEZiMplLoX5b7ep4rhtTXYnVRAfuf8/PyVK1cWFRUZDIaioqITJ05kZGQAANRqNQDg+++/v3btWkJCAoZheXl5JpPp5s2bmzdvzsrKampqcpthTEzM1atXL1y40NHRwXi0JEHrWwiPVWDaAwe2NVRfNnlKhaGpqWnFihUajUaj0UycODE3N9dqtbqSVq9enZWVtXjxYpqmjx49OnPmTI1GM2PGjPLy8h9++EGj0cydO/fWrVsajaa4uLgrw+Li4unTp48YMeL8+fOMR1tVajyU2+Ap1WNr89VTnY03bROe7Mf479m3KPxS2z9ZmDrSfdeYx2feZI2krtLivbXrvsfYQdbfsD7guaXdW19H2Ql9403b5IXum0sbGhq6qr73wGKxnE739cxZs2YtXbrUj8h7wvLly0tLS90myeVyvV7vNmn9+vWjR492m1TwWZP6AWFGtsdWO2/6nBT4n3dqRk9TJWa4aXpxOp1ms9ntgTabzVO9jMPhBK7KZrFYKMp9hYEgCA7HfY++QCBgs93cWCsvGs8U6J5aHeet1c77hbOlzpb7WnW71sH4JTnEaWu0575W3VJn876bj+ZQlZo3YUHk4U8bHTb3J+N9icPmPLyzcfLCKJ/NTn51k1dcNJb+pJ+6KFokC1Q7Quhg0pOHP20a+qjcn75ZfwdpNFRbj+9pmbAgMiI2UO2AoUDLbXvhbm3OvH5R8X5doLsxRMjQTh7KbYhPE4+YqGDfd91vhIM+d0RXV2GZsihaqvC3rbN7A9Qogi4/Z6i4aBw0SpaYIebw7geJhN1ZVWa6dsaQmiX1VD32RA+HR968ar51xWzSE8oonljO5otwvgjvKz3ChIO2mSmbmTLpybYmuySMk5Auiu+d4ZH30HTL1q51dLYR+laHzcLw3Vmn0wEAlEols9nyRSx5OFem4igjuZFxwRic2zvs2LEDw7Dnnnsu2IF45N+7GxwapA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA8KpA+KUHwtZsqUKRRF0TRttVoBACKRiKIoDodz+PDhYId2L4GaJg2GqKiokpKSrsltXK/YZ2ZmBjsuN4TiyTtnzhy5/DfTkyuVyq45rEKKUNSXk5OTlJR095a4uLhHHnkkeBF5JBT1ueYrkcnuTP8hl8vnzZsX7IjcE6L6xo0bFxcX5/o8YMCAsWPHBjsi94SoPgDA7NmzRSKRSCSaPXt2sGPxCPN33o5mwmJkYOqmtITslLjROI6nJWQ3VFnhMxRK2GH9GF7bhsl635nDuopiI0+Ic3ihWKgJu9NuoVKypFmTGVvBgBl9Dpvzu60Nin68hx6PYCKqAHJyf7NB55jxfAwjvzEz+r7f3UwDbFTIu3Nxan8LzqHHz2Ngbj0GfoHWent9pWX4xD6zhtGIyeG11yztWgbmtmVAX3OtTT1Q1IfmdOHwWP0HirQ1NvisGNDXqSNk4b06uz08MhVX30rA58OAvtBrsvELp5OBuEOxhtGHQPqgQPqgQPqgQPqgQPqgQPqgQPqgQPqgQPqgQPqgCC19M2dN+vyL7cGOohuElr6eseaNvxYW5gflq+8HfZU3fgnWVwdnjAtFUXv+d/eXuz/BMCwtNeMvzy5NSRnkWrSJzeZ8uzcv95MtPB4vI2PYa6vWicViAMDp0yeOHS+8fKXEZDIOShv85IJF6elDaJoemzMcALDhvTcPHNr78dYvevkfCU7p27b9g4KC/evWbvr7a+vlYYqVq15oaKx3JR07XkgQxHv/vfWVl18vLb2w68tc1wIg72x4naKoV1etXf/2+ypVv9dWLzcYDRiGHTl8EgCwauWbve8uOKWvs1P/f999/fKK1cMzRwIAMjNHvr1+dbuuLSZaDQCQSKTz5i507VlUdKys7KJrUbtPcr8WCoQymRwAkBCfVHDkQEVFuSuHIBIEfbduVQMABg68s2Iij8dbt3ZjV2r6oCFdn8ViCUHeaVK3mM07d24tu3xJp2tzbWn/9UMQCcLJazIbAQA8rpuFK2iavnvdGwzDXGseabVN//XSIqfT+frqd34oPHv40IneDdkjQSh9AoEQAGCxdmMRx2PHCymK+tvKN13rHOlCoNy5CELpS05OwXH88uVLrj+dTufKv73w/8cKvRxiNpvEYknXGlFFJ4/1SqS+CYI+iVgyYfyUAwe+PVp4qKT0wodb3iu7fCktNcPLIfHxSW1trYcL9pMkefbsyfLyK2KxuLlF67qrKJXhFy6eLf/lai/+E3cITsXlxWUr0wYN3rjp7RUvLy4vv/L2un9GRkZ52X/c2Inz5i789LOPx08ceeDQ3mUv/HX8+Cmff7F9y0cbAQDz5iw8d+7Ulq3/6MX/4A4MjHE5eaCNw2OnPiT3Y99Q4dppPekgH54WDpnP/fDQFkSQPiiQPiiQPiiQPiiQPiiQPiiQPiiQPiiQPiiQPiiQPiiQPiiYeDGpz7zQ8RsYCZsBfVIlx9jOwDsSvYlB55CFM/B2JQP6VDE8bQ0DL4z2Jtoaa4QaamVeFwzoi4zji+X4uYJW+Kx6hzOHWuQqDiNr1DP2Quq+jxrYXFbmBJUiMnRf0GrXOoqPtlKkc/rzMVx+yLyQ6uJsge7KqU4OlyWWM/PStpOmAQAshu5Nxg6CIp3po+Uh9zr03bRrHVYTxUhWhw4dAgA89thjjOQWiJfxme8mZ/DkxYQdGIbFJAmYypBxULUZCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPCqQPilBcm3zq1KmNjY00TXetr03TdHR0dAiuTR6KpW/q1Kk4juM4zvoVNpv9+OOPBzsuN4SivlmzZqnV6ru3xMbGzpkzJ3gReSQU9SkUikmTJnWduRiG5eTkdK21HVKEoj4AwMyZM/v37+/6rFar586dG+yI3BOi+pRKZU5ODoZhGIZNmjRJLg/RmT1DVJ9rbfLY2NiYmJhQXpucgYqLuZOsKjN16kirkbKZKbudsZpQa0srwIBKxdjKvzwexhfhQgkuVbKTBotFMtjXmXuujyLoS8f1lSVGg46QR4nYPA7OxdkcHGeHbommSCdJUBRBkRZC32yWKrkpw8WDs+U4p4fv+/dQX+UlU9G+Vo6IGxYllUQIe/bdQcfQYtE3GQizI3u6KnmYuAc5dFuf3erM/0TbqacikxTCMAamQgk65nZrc1WHTIE//lxUd9e47p4+Qzu5b2uDSCUJjwvFWhgMrbf01g7zn5ZESxXduCB2Q1/zbVvBZ82qZKU4LHTnZoDBpLO1VLU9tihSpfZ3hhx/L/MWA3X4s+botIj71R0AQKzkR6dF5H+qNRv8nUjFL30kQe/7uCEiUckTh+4MQYzAF3NVicoD2xsp0q+T0i99ZwvahQqxOPy+LXd3I1YK+DLhuaPt/uzsW5+5k6opt4T1v9/uFV5QxMqrL1vMnaTPPX3r+/m7VllMiD5yBg5ZtKzogM7nbj702czO+iqrRBWiFeMOvfaV17PKr59kPGdphKi23Gwz+7iH+NBXVWaUqkSMBtZHwIC0n+jmVZP3vXzou1FqFoWHaNELNGKFsKrUx3JePmrYrXW2xFGMNXjcQ6eh9eCRD2rrrhCE/cEHHhr/6KJwpRoAUHRmz/Gi3f+5cMuub1a1tNZERT7w6MNPDhs80XXUpcuFhT/usNnNqQ9mP5z1ZxCwyWcFcl7NeR8rmnkrfSRBkyQdoBYUiiK3f/58bd2VWX/6+yvLvhYIJB/mPtuh1wIA2Gyu1WbYX7Bp9vS//2Pt2bSB2Xv2rTWa2gEATc1VX+99Iytz2qrle4emT9hf8M9AxOaCzcUJwrXMnke8qelsIwRihucL7OJmTUlrW+3cJ95MThohESsem7ScxxUUndnj6twgCPukcYsH9E/HMEwzZDJFkQ2NFQCAk2e/VYTFjP3D0wKBJDlpxIhhzMyM6Am+kN3Z5m1SYG/6THqSzcMDEBUAANTcvszl8BPjh7n+xHE8LnZwze0yV68uACBWneZK4vPFAACb3QQA0LXX94uI78pEHZMCAAjcvNEcAduk91b783btY3OxwPWh2+xmB2F75fWsuzeGyaMAAICmXWXw7iSXU6vVKBaFdW3ksHldSYGAomjca/nxpk8oxim775p3z5CIlXyeaOG836xNx/IeLAB8vthB2Lr+dBDW34tmENJOCaVeS5iXNIGE7bAxM4nr74mKTLLZzWHySKUixrWlrb1eKvax7lyYPLKy6lzX+I3rlacDWvoIKymUePtFvV37+EIWm8sibAEpgAOTspKTsr498I6+s9lk7ig6s+eDbU9fLDvi/aiMtHEGY1t+4RYAwI3q4rMX9oOAVVwcFpLDx71P7+yj3hf7oNDYalH0lzIdGwAALHrygzPF3+3es7q27kqEKi5LM+2h4dO9H5I6cPQfJzx/tnjfz6fywuRRc2as2fbZEqczIKeIsc0SP8jHE5eP1ubqMtOZo53qjEimY+sD1JdpR02VJ3g16KNKrE4WdrZYHZZA3UBCFoeVNLRa+yf7eGD1cfLyBKyBGqn2Zod6kPtHN4oi39gw0W0SSTrYONdtrSwmKnnJs9u8f3W3eH19Dg3cn0ZOJ8Viubn8x6rTnnv6Q08ZtlS1Dxwu5XB9XFV9dxVZTdSudTVxmdF8Dy317R2NbrfbbCZXjff34DhHJmXyUdpTDAAAB2Hnctx0/bDZXKnE/Y3eZnTUXmpa+EYcT+Dj7PSrp63kp45Lxw3xw6NZeOiOIGAKJ+m8Vdw4fLwsI9t3I7FfOob8Qa6K5tRfbQ3BkbzMQtN03eXm8GhO+mi/Oif80oexsD8+G8XBKW2FXx0ofZem6+1cLj3lL1EYy6+6pL8nI5uDTV8aDUj77dJmp3+deH0LJ0nfLm3GnI7pS2PYfo8Y6t4gDYqkj3yhbb7tiB0ayeEzv1hFsCBsZO0lbXQCb+KT/XB2N55hejLC6sL3HReOdYTHyhSxMhbeN5cZ+xWKottr9brbhszxYZk5YX4c8Rt6OECto5ko+Vl/66pZKBcK5DyxUsDmBqplMBCQNsrUYbV02q0dloR00dAxcrmqJw3DUKNLSYKuuWapLDXX/WKiAcYXc7hCDpsXoic1TQPKQToshM3swGgQmyp+YKgoKQOqH5Gxt4pMelLfSnS2Ef50zgcHDIikbFk4R67iiOXM/Mah+FJWH+L+f4oIKEgfFEgfFEgfFEgfFEgfFP8Cw5Ogsfz5xzQAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(session.agent.graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's nice to meet you too, Ricky! I'm an artificial intelligence created by Anthropic. I don't have a physical form, but I'm happy to chat and try my best to assist you with any questions or tasks you may have. Please let me know if there's anything I can help with.\n"
     ]
    }
   ],
   "source": [
    "# Interact\n",
    "print(session.send(\"my name is Ricky nice to meet you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Ricky. You introduced yourself as Ricky at the beginning of our conversation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(session.send(\"what is my name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: my name is Ricky nice to meet you\n",
      "Bot: It's nice to meet you too, Ricky! I'm an artificial intelligence created by Anthropic. I don't have a physical form, but I'm happy to chat and try my best to assist you with any questions or tasks you may have. Please let me know if there's anything I can help with.\n",
      "You: what is my name?\n",
      "Bot: Your name is Ricky. You introduced yourself as Ricky at the beginning of our conversation.\n"
     ]
    }
   ],
   "source": [
    "# Show memory\n",
    "for line in session.history():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2430a34b7733441abbc3d103868caad95c6aa1c312dbfb921277c98bf08bf297"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
