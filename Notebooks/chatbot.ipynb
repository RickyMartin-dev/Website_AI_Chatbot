{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "bedrock = boto3.client('bedrock', region_name=os.getenv(\"AWS_REGION\"))\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=os.getenv(\"AWS_REGION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Model Specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large', 'modelId': 'amazon.titan-tg1-large', 'modelName': 'Titan Text Large', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0', 'modelId': 'amazon.titan-image-generator-v1:0', 'modelName': 'Titan Image Generator G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1', 'modelId': 'amazon.titan-image-generator-v1', 'modelName': 'Titan Image Generator G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v2:0', 'modelId': 'amazon.titan-image-generator-v2:0', 'modelName': 'Titan Image Generator G1 v2', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED', 'ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:8k', 'modelId': 'amazon.nova-premier-v1:0:8k', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:20k', 'modelId': 'amazon.nova-premier-v1:0:20k', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:1000k', 'modelId': 'amazon.nova-premier-v1:0:1000k', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:mm', 'modelId': 'amazon.nova-premier-v1:0:mm', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0', 'modelId': 'amazon.nova-premier-v1:0', 'modelName': 'Nova Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-premier-v1:0', 'modelId': 'amazon.titan-text-premier-v1:0', 'modelName': 'Titan Text G1 - Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:24k', 'modelId': 'amazon.nova-pro-v1:0:24k', 'modelName': 'Nova Pro', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:300k', 'modelId': 'amazon.nova-pro-v1:0:300k', 'modelName': 'Nova Pro', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'DISTILLATION'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0', 'modelId': 'amazon.nova-pro-v1:0', 'modelName': 'Nova Pro', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:24k', 'modelId': 'amazon.nova-lite-v1:0:24k', 'modelName': 'Nova Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:300k', 'modelId': 'amazon.nova-lite-v1:0:300k', 'modelName': 'Nova Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'DISTILLATION'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0', 'modelId': 'amazon.nova-lite-v1:0', 'modelName': 'Nova Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-canvas-v1:0', 'modelId': 'amazon.nova-canvas-v1:0', 'modelName': 'Nova Canvas', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'responseStreamingSupported': False, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:0', 'modelId': 'amazon.nova-reel-v1:0', 'modelName': 'Nova Reel', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['VIDEO'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:1', 'modelId': 'amazon.nova-reel-v1:1', 'modelName': 'Nova Reel', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['VIDEO'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:24k', 'modelId': 'amazon.nova-micro-v1:0:24k', 'modelName': 'Nova Micro', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:128k', 'modelId': 'amazon.nova-micro-v1:0:128k', 'modelName': 'Nova Micro', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'DISTILLATION'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0', 'modelId': 'amazon.nova-micro-v1:0', 'modelName': 'Nova Micro', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-sonic-v1:0', 'modelId': 'amazon.nova-sonic-v1:0', 'modelName': 'Nova Sonic', 'providerName': 'Amazon', 'inputModalities': ['SPEECH'], 'outputModalities': ['SPEECH', 'TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02', 'modelId': 'amazon.titan-embed-g1-text-02', 'modelName': 'Titan Text Embeddings v2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k', 'modelId': 'amazon.titan-text-lite-v1:0:4k', 'modelName': 'Titan Text G1 - Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1', 'modelId': 'amazon.titan-text-lite-v1', 'modelName': 'Titan Text G1 - Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k', 'modelId': 'amazon.titan-text-express-v1:0:8k', 'modelName': 'Titan Text G1 - Express', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1', 'modelId': 'amazon.titan-text-express-v1', 'modelName': 'Titan Text G1 - Express', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k', 'modelId': 'amazon.titan-embed-text-v1:2:8k', 'modelName': 'Titan Embeddings G1 - Text', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1', 'modelId': 'amazon.titan-embed-text-v1', 'modelName': 'Titan Embeddings G1 - Text', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0:8k', 'modelId': 'amazon.titan-embed-text-v2:0:8k', 'modelName': 'Titan Text Embeddings V2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0', 'modelId': 'amazon.titan-embed-text-v2:0', 'modelName': 'Titan Text Embeddings V2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0', 'modelId': 'amazon.titan-embed-image-v1:0', 'modelName': 'Titan Multimodal Embeddings G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1', 'modelId': 'amazon.titan-embed-image-v1', 'modelName': 'Titan Multimodal Embeddings G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0', 'modelId': 'stability.stable-diffusion-xl-v1:0', 'modelName': 'SDXL 1.0', 'providerName': 'Stability AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1', 'modelId': 'stability.stable-diffusion-xl-v1', 'modelName': 'SDXL 1.0', 'providerName': 'Stability AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-instruct-v1:0', 'modelId': 'ai21.jamba-instruct-v1:0', 'modelName': 'Jamba-Instruct', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-large-v1:0', 'modelId': 'ai21.jamba-1-5-large-v1:0', 'modelName': 'Jamba 1.5 Large', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-mini-v1:0', 'modelId': 'ai21.jamba-1-5-mini-v1:0', 'modelName': 'Jamba 1.5 Mini', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k', 'modelId': 'anthropic.claude-instant-v1:2:100k', 'modelName': 'Claude Instant', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1', 'modelId': 'anthropic.claude-instant-v1', 'modelName': 'Claude Instant', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k', 'modelId': 'anthropic.claude-v2:0:18k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k', 'modelId': 'anthropic.claude-v2:0:100k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k', 'modelId': 'anthropic.claude-v2:1:18k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k', 'modelId': 'anthropic.claude-v2:1:200k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1', 'modelId': 'anthropic.claude-v2:1', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2', 'modelId': 'anthropic.claude-v2', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:28k', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:200k', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:48k', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:200k', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:12k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:28k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:200k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0', 'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'modelName': 'Claude 3.5 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND', 'INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20241022-v2:0', 'modelId': 'anthropic.claude-3-5-sonnet-20241022-v2:0', 'modelName': 'Claude 3.5 Sonnet v2', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-7-sonnet-20250219-v1:0', 'modelId': 'anthropic.claude-3-7-sonnet-20250219-v1:0', 'modelName': 'Claude 3.7 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-haiku-20241022-v1:0', 'modelId': 'anthropic.claude-3-5-haiku-20241022-v1:0', 'modelName': 'Claude 3.5 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-20250514-v1:0', 'modelId': 'anthropic.claude-opus-4-20250514-v1:0', 'modelName': 'Claude Opus 4', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-sonnet-4-20250514-v1:0', 'modelId': 'anthropic.claude-sonnet-4-20250514-v1:0', 'modelName': 'Claude Sonnet 4', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k', 'modelId': 'cohere.command-text-v14:7:4k', 'modelName': 'Command', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14', 'modelId': 'cohere.command-text-v14', 'modelName': 'Command', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-v1:0', 'modelId': 'cohere.command-r-v1:0', 'modelName': 'Command R', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-plus-v1:0', 'modelId': 'cohere.command-r-plus-v1:0', 'modelName': 'Command R+', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k', 'modelId': 'cohere.command-light-text-v14:7:4k', 'modelName': 'Command Light', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14', 'modelId': 'cohere.command-light-text-v14', 'modelName': 'Command Light', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3:0:512', 'modelId': 'cohere.embed-english-v3:0:512', 'modelName': 'Embed English', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3', 'modelId': 'cohere.embed-english-v3', 'modelName': 'Embed English', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3:0:512', 'modelId': 'cohere.embed-multilingual-v3:0:512', 'modelName': 'Embed Multilingual', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3', 'modelId': 'cohere.embed-multilingual-v3', 'modelName': 'Embed Multilingual', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/deepseek.r1-v1:0', 'modelId': 'deepseek.r1-v1:0', 'modelName': 'DeepSeek-R1', 'providerName': 'DeepSeek', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0', 'modelId': 'meta.llama3-8b-instruct-v1:0', 'modelName': 'Llama 3 8B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0', 'modelId': 'meta.llama3-70b-instruct-v1:0', 'modelName': 'Llama 3 70B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-8b-instruct-v1:0', 'modelId': 'meta.llama3-1-8b-instruct-v1:0', 'modelName': 'Llama 3.1 8B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-70b-instruct-v1:0', 'modelId': 'meta.llama3-1-70b-instruct-v1:0', 'modelName': 'Llama 3.1 70B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-11b-instruct-v1:0', 'modelId': 'meta.llama3-2-11b-instruct-v1:0', 'modelName': 'Llama 3.2 11B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-90b-instruct-v1:0', 'modelId': 'meta.llama3-2-90b-instruct-v1:0', 'modelName': 'Llama 3.2 90B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-1b-instruct-v1:0', 'modelId': 'meta.llama3-2-1b-instruct-v1:0', 'modelName': 'Llama 3.2 1B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-3b-instruct-v1:0', 'modelId': 'meta.llama3-2-3b-instruct-v1:0', 'modelName': 'Llama 3.2 3B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-3-70b-instruct-v1:0', 'modelId': 'meta.llama3-3-70b-instruct-v1:0', 'modelName': 'Llama 3.3 70B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0', 'modelId': 'meta.llama4-scout-17b-instruct-v1:0', 'modelName': 'Llama 4 Scout 17B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-maverick-17b-instruct-v1:0', 'modelId': 'meta.llama4-maverick-17b-instruct-v1:0', 'modelName': 'Llama 4 Maverick 17B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-7b-instruct-v0:2', 'modelId': 'mistral.mistral-7b-instruct-v0:2', 'modelName': 'Mistral 7B Instruct', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mixtral-8x7b-instruct-v0:1', 'modelId': 'mistral.mixtral-8x7b-instruct-v0:1', 'modelName': 'Mixtral 8x7B Instruct', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-2402-v1:0', 'modelId': 'mistral.mistral-large-2402-v1:0', 'modelName': 'Mistral Large (24.02)', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-small-2402-v1:0', 'modelId': 'mistral.mistral-small-2402-v1:0', 'modelName': 'Mistral Small (24.02)', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.pixtral-large-2502-v1:0', 'modelId': 'mistral.pixtral-large-2502-v1:0', 'modelName': 'Pixtral Large (25.02)', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n"
     ]
    }
   ],
   "source": [
    "response = bedrock.list_foundation_models()\n",
    "models = response['modelSummaries']\n",
    "\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon.titan-tg1-large', 'amazon.titan-image-generator-v1:0', 'amazon.titan-image-generator-v1', 'amazon.titan-image-generator-v2:0', 'amazon.nova-premier-v1:0:8k', 'amazon.nova-premier-v1:0:20k', 'amazon.nova-premier-v1:0:1000k', 'amazon.nova-premier-v1:0:mm', 'amazon.nova-premier-v1:0', 'amazon.titan-text-premier-v1:0', 'amazon.nova-pro-v1:0:24k', 'amazon.nova-pro-v1:0:300k', 'amazon.nova-pro-v1:0', 'amazon.nova-lite-v1:0:24k', 'amazon.nova-lite-v1:0:300k', 'amazon.nova-lite-v1:0', 'amazon.nova-canvas-v1:0', 'amazon.nova-reel-v1:0', 'amazon.nova-reel-v1:1', 'amazon.nova-micro-v1:0:24k', 'amazon.nova-micro-v1:0:128k', 'amazon.nova-micro-v1:0', 'amazon.nova-sonic-v1:0', 'amazon.titan-embed-g1-text-02', 'amazon.titan-text-lite-v1:0:4k', 'amazon.titan-text-lite-v1', 'amazon.titan-text-express-v1:0:8k', 'amazon.titan-text-express-v1', 'amazon.titan-embed-text-v1:2:8k', 'amazon.titan-embed-text-v1', 'amazon.titan-embed-text-v2:0:8k', 'amazon.titan-embed-text-v2:0', 'amazon.titan-embed-image-v1:0', 'amazon.titan-embed-image-v1', 'stability.stable-diffusion-xl-v1:0', 'stability.stable-diffusion-xl-v1', 'ai21.jamba-instruct-v1:0', 'ai21.jamba-1-5-large-v1:0', 'ai21.jamba-1-5-mini-v1:0', 'anthropic.claude-instant-v1:2:100k', 'anthropic.claude-instant-v1', 'anthropic.claude-v2:0:18k', 'anthropic.claude-v2:0:100k', 'anthropic.claude-v2:1:18k', 'anthropic.claude-v2:1:200k', 'anthropic.claude-v2:1', 'anthropic.claude-v2', 'anthropic.claude-3-sonnet-20240229-v1:0:28k', 'anthropic.claude-3-sonnet-20240229-v1:0:200k', 'anthropic.claude-3-sonnet-20240229-v1:0', 'anthropic.claude-3-haiku-20240307-v1:0:48k', 'anthropic.claude-3-haiku-20240307-v1:0:200k', 'anthropic.claude-3-haiku-20240307-v1:0', 'anthropic.claude-3-opus-20240229-v1:0:12k', 'anthropic.claude-3-opus-20240229-v1:0:28k', 'anthropic.claude-3-opus-20240229-v1:0:200k', 'anthropic.claude-3-opus-20240229-v1:0', 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'anthropic.claude-3-5-sonnet-20241022-v2:0', 'anthropic.claude-3-7-sonnet-20250219-v1:0', 'anthropic.claude-3-5-haiku-20241022-v1:0', 'anthropic.claude-opus-4-20250514-v1:0', 'anthropic.claude-sonnet-4-20250514-v1:0', 'cohere.command-text-v14:7:4k', 'cohere.command-text-v14', 'cohere.command-r-v1:0', 'cohere.command-r-plus-v1:0', 'cohere.command-light-text-v14:7:4k', 'cohere.command-light-text-v14', 'cohere.embed-english-v3:0:512', 'cohere.embed-english-v3', 'cohere.embed-multilingual-v3:0:512', 'cohere.embed-multilingual-v3', 'deepseek.r1-v1:0', 'meta.llama3-8b-instruct-v1:0', 'meta.llama3-70b-instruct-v1:0', 'meta.llama3-1-8b-instruct-v1:0', 'meta.llama3-1-70b-instruct-v1:0', 'meta.llama3-2-11b-instruct-v1:0', 'meta.llama3-2-90b-instruct-v1:0', 'meta.llama3-2-1b-instruct-v1:0', 'meta.llama3-2-3b-instruct-v1:0', 'meta.llama3-3-70b-instruct-v1:0', 'meta.llama4-scout-17b-instruct-v1:0', 'meta.llama4-maverick-17b-instruct-v1:0', 'mistral.mistral-7b-instruct-v0:2', 'mistral.mixtral-8x7b-instruct-v0:1', 'mistral.mistral-large-2402-v1:0', 'mistral.mistral-small-2402-v1:0', 'mistral.pixtral-large-2502-v1:0']\n"
     ]
    }
   ],
   "source": [
    "response = bedrock.list_foundation_models()\n",
    "print([model[\"modelId\"] for model in response[\"modelSummaries\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple App Testing using Langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrock_llm(model_id: str = \"anthropic.claude-3-haiku-20240307-v1:0\", temp: float = 0.7, max_tokens: int = 2048):\n",
    "    \"\"\"Initialize a Bedrock LLM instance with the specific model\"\"\"\n",
    "    llm = ChatBedrock(client=bedrock_runtime,\n",
    "        model_id=model_id,\n",
    "        streaming=True,\n",
    "        model_kwargs=dict(temperature=temp, max_tokens=max_tokens))\n",
    "    return llm\n",
    "\n",
    "llm = get_bedrock_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm doing well, thank you for asking! As an AI language model, I don't have feelings or a physical state, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\", additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None, 'model_name': 'anthropic.claude-3-haiku-20240307-v1:0'}, id='run--85ac8889-d400-4af7-bc18-f30b0794000c-0', usage_metadata={'input_tokens': 12, 'output_tokens': 55, 'total_tokens': 67, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing The Actual App/Graph Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, boto3, json\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a pirate assistant.\n",
      "USER: Ahoy! How are ye?\n",
      "ASSISTANT:  I'm doing well, thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\")\n",
    "MODEL_ID = \"anthropic.claude-v2\"#\"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "DEFAULT_SYSTEM_PROMPT = os.getenv(\"DEFAULT_SYSTEM_PROMPT\", \"You are a helpful assistant.\")\n",
    "\n",
    "# Load config\n",
    "load_dotenv()\n",
    "\n",
    "# Bedrock call\n",
    "def get_bedrock_response(prompt: str, temperature=0.7, max_tokens=300):\n",
    "    bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    body = {\n",
    "        \"prompt\": f\"\\n\\nHuman: {prompt}\\n\\nAssistant:\",\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens_to_sample\": max_tokens\n",
    "    }\n",
    "    resp = bedrock.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "    return json.loads(resp[\"body\"].read())[\"completion\"]\n",
    "\n",
    "# TypedDict for state\n",
    "class ChatState(TypedDict):\n",
    "    messages: list[dict]\n",
    "\n",
    "# Node definition\n",
    "def call_llm_node(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    reply = get_bedrock_response(user_msg)\n",
    "    # Append assistant message\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "# Build the graph\n",
    "def build_graph():\n",
    "    builder = StateGraph(ChatState)\n",
    "    builder.add_node(\"call_llm\", call_llm_node)\n",
    "\n",
    "    # Core routing\n",
    "    builder.add_edge(START, \"call_llm\")\n",
    "    builder.set_finish_point(\"call_llm\")  # Halts after the node\n",
    "    return builder.compile()\n",
    "\n",
    "# Instantiate graph\n",
    "graph = build_graph()\n",
    "\n",
    "# Run a conversation\n",
    "def run_conversation(initial_messages: list[dict]) -> list[dict]:\n",
    "    # initial_messages includes system + user\n",
    "    state: ChatState = {\"messages\": initial_messages.copy()}\n",
    "    result = graph.invoke(state)\n",
    "    return result[\"messages\"]\n",
    "\n",
    "# Test example\n",
    "initial = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Ahoy! How are ye?\"}\n",
    "]\n",
    "chat = run_conversation(initial)\n",
    "for m in chat:\n",
    "    print(f\"{m['role'].upper()}: {m['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a pirate assistant.\n",
      "USER: Ahoy! How are ye?\n",
      "ASSISTANT: *tips pirate hat* Ahoy there, matey! As chipper as a pirate with a chest full of doubloons. How be ye faring on this fine day? Ready to set sail on some high seas adventures?\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\")\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "DEFAULT_SYSTEM_PROMPT = os.getenv(\"DEFAULT_SYSTEM_PROMPT\", \"You are a helpful assistant.\")\n",
    "\n",
    "# Load config\n",
    "load_dotenv()\n",
    "\n",
    "# Bedrock call\n",
    "def get_bedrock_response(prompt: str, temperature=0.7, max_tokens=300):\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    response = client.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    result = json.loads(response[\"body\"].read())\n",
    "    return result[\"content\"][0][\"text\"]  # Extract response\n",
    "\n",
    "# TypedDict for state\n",
    "class ChatState(TypedDict):\n",
    "    messages: list[dict]\n",
    "\n",
    "# Node definition\n",
    "def call_llm_node(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    reply = get_bedrock_response(user_msg)\n",
    "    # Append assistant message\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "# Build the graph\n",
    "def build_graph():\n",
    "    builder = StateGraph(ChatState)\n",
    "    builder.add_node(\"call_llm\", call_llm_node)\n",
    "\n",
    "    # Core routing\n",
    "    builder.add_edge(START, \"call_llm\")\n",
    "    builder.set_finish_point(\"call_llm\")  # Halts after the node\n",
    "    return builder.compile()\n",
    "\n",
    "# Instantiate graph\n",
    "graph = build_graph()\n",
    "\n",
    "# Run a conversation\n",
    "def run_conversation(initial_messages: list[dict]) -> list[dict]:\n",
    "    # initial_messages includes system + user\n",
    "    state: ChatState = {\"messages\": initial_messages.copy()}\n",
    "    result = graph.invoke(state)\n",
    "    return result[\"messages\"]\n",
    "\n",
    "# Test example\n",
    "initial = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Ahoy! How are ye?\"}\n",
    "]\n",
    "chat = run_conversation(initial)\n",
    "for m in chat:\n",
    "    print(f\"{m['role'].upper()}: {m['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a pirate assistant.\n",
      "USER: Why is the ocean blue?\n",
      "ASSISTANT: The ocean appears blue because of a phenomenon called scattering, where shorter (blue) wavelengths of light are dispersed more than longer (red) wavelengths by the tiny molecules of gases in the atmosphere and by the water itself. Here's a more detailed explanation:\n",
      "\n",
      "1. **Sunlight and the atmosphere**: When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2). These molecules scatter the shorter wavelengths of light, like blue and violet, more than the longer wavelengths, like red and orange. This is known as Rayleigh scattering.\n",
      "\n",
      "2. **Scattering in the ocean**: Once the light penetrates the ocean's surface, it continues to scatter. Water molecules and other substances in the ocean scatter the light in all directions. Again, the shorter wavelengths (like blue light) are scattered more than the longer wavelengths.\n",
      "\n",
      "3. **Absorption by water**: Water itself absorbs light, but it absorbs longer wavelengths (like red and infrared) more than the shorter wavelengths (like blue and violet). This means that as light travels through the water, the red light is absorbed, leaving mainly blue light to be scattered and reach our eyes.\n",
      "\n",
      "4. **Other factors**: While the basic reason for the ocean's blue color is the scattering and absorption of light, other factors can influence the color we perceive. These include the presence of sediments, algae, or other substances that can absorb or scatter light in different ways. For example, high concentrations of phytoplankton can give the ocean a greenish hue.\n",
      "\n",
      "In summary, the ocean appears blue primarily because of the scattering of sunlight by the atmosphere and the water itself, combined with the absorption of longer wavelengths by water. This results in the blue color being predominant as it is scattered in all directions and reaches our eyes from the ocean.\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = os.getenv(\"MODEL_PROFILE_ID\", \"us.meta.llama4-maverick-17b-instruct-v1:0\")\n",
    "\n",
    "# Define state schema\n",
    "class ChatState(TypedDict):\n",
    "    messages: list[dict]\n",
    "\n",
    "# Bedrock request with inference profile\n",
    "def get_bedrock_response(prompt: str, temperature=0.5, max_gen_len=512, top_p=0.9):\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "    formatted = (\n",
    "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\"\n",
    "        \"You are a helpful assistant.\\n<|eot_id|>\\n\"\n",
    "        + \"\".join(\n",
    "            f\"<|start_header_id|>{m['role']}<|end_header_id|>\\n{m['content']}\\n<|eot_id|>\\n\"\n",
    "            for m in [{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        + \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    )\n",
    "    body = {\n",
    "        \"prompt\": formatted,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_gen_len\": max_gen_len,\n",
    "        \"top_p\": top_p\n",
    "    }\n",
    "    resp = client.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    data = json.loads(resp[\"body\"].read())\n",
    "    return data.get(\"generation\", \"\").strip()\n",
    "\n",
    "# LangGraph node\n",
    "def call_llm_node(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"messages\"][-1][\"content\"]\n",
    "    reply = get_bedrock_response(user_msg)\n",
    "    state[\"messages\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return state\n",
    "\n",
    "# Build graph\n",
    "def build_graph():\n",
    "    builder = StateGraph(ChatState)\n",
    "    builder.add_node(\"call_llm\", call_llm_node)\n",
    "    builder.add_edge(START, \"call_llm\")\n",
    "    builder.set_finish_point(\"call_llm\")\n",
    "    return builder.compile()\n",
    "\n",
    "graph = build_graph()\n",
    "\n",
    "# Conversation runner\n",
    "def run_conversation(initial_messages: list[dict]) -> list[dict]:\n",
    "    state: ChatState = {\"messages\": initial_messages.copy()}\n",
    "    return graph.invoke(state)[\"messages\"]\n",
    "\n",
    "# Test it\n",
    "initial = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Why is the ocean blue?\"}\n",
    "]\n",
    "chat = run_conversation(initial)\n",
    "for m in chat:\n",
    "    print(f\"{m['role'].upper()}: {m['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2430a34b7733441abbc3d103868caad95c6aa1c312dbfb921277c98bf08bf297"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
